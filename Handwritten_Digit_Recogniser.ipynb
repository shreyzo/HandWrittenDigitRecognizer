{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten Digit Recogniser",
      "provenance": [],
      "authorship_tag": "ABX9TyOBp5pDRnOELl1QAzMtlK1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shreyzo/HandWrittenDigitRecognizer/blob/master/Handwritten_Digit_Recogniser.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bzu5a2HfF6m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dca64c5f-9f15-4714-9171-4d1e26c37c5d"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework import ops\n",
        "\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJRfnmIMiZrk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loaddataset():\n",
        "    (trainX, trainy),  (testX, testy) = mnist.load_data()\n",
        "    trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "    testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "    # one hot encode target values\n",
        "    #trainY = to_categorical(trainY)\n",
        "    #testY = to_categorical(testY)\n",
        "    return trainX, trainy, testX, testy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6Ryf_I1ifJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_function():\n",
        "    X = tf.constant(np.random.randn(3,1),name=\"X\")\n",
        "    W = tf.constant(np.random.randn(4,3),name=\"W\")\n",
        "    b = tf.constant(np.random.randn(4,1),name=\"b\")\n",
        "    Y = tf.add(tf.matmul(W,X),b)\n",
        "    \n",
        "    tf.compat.v1.disable_eager_execution() \n",
        "    sess = tf.compat.v1.Session()\n",
        "    result = sess.run(Y)\n",
        "    \n",
        "    sess.close()\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5CkkOW8iggK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX, trainy, testX, testy = loaddataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0l1_cSZig56",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(z):\n",
        "    x = tf.compat.v1.placeholder(tf.float32, name=\"x\")\n",
        "    \n",
        "    sigmoid = tf.sigmoid(x)\n",
        "    \n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        result= sess.run(sigmoid, feed_dict = {x:z})\n",
        "    \n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHl2sCVfig9H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cost(logits, labels):\n",
        "    z = tf.compat.v1.placeholder(tf.float32, name=\"z\")\n",
        "    y = tf.compat.v1.placeholder(tf.float32, name=\"y\")\n",
        "    \n",
        "    cost = tf.nn.sigmoid_cross_entropy_with_logits(logits = z, labels = y)\n",
        "    \n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        cost = sess.run(cost, feed_dict = {z:logits, y:labels})\n",
        "\n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IaIUVEhio4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGABR3I_io8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 262144, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches\n",
        "\n",
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y\n",
        "\n",
        "\n",
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.compat.v1.placeholder(\"float\", [784, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.compat.v1.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction\n",
        "\n",
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3'] \n",
        "                                                           # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
        "    \n",
        "    return Z3\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "153BRijGipA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "486efd08-4eb4-4f0e-a69c-a6c8571b7547"
      },
      "source": [
        "def one_hot_matrix(labels, C):\n",
        "    C = tf.constant(C, name=\"C\")\n",
        "    \n",
        "    one_hot_matrix = tf.one_hot(labels,C,axis=0)\n",
        " \n",
        "    sess = tf.compat.v1.Session()\n",
        "    one_hot = sess.run(one_hot_matrix)\n",
        "    \n",
        "    sess.close()\n",
        "    \n",
        "    return one_hot\n",
        "\n",
        "\"\"\"test: one_hot_matrix(labels, C)\n",
        "labels = np.array([1,2,3,0,2,1])\n",
        "one_hot = one_hot_matrix(labels, C = 4)\n",
        "print (\"one_hot = \\n\" + str(one_hot))\n",
        "\n",
        "output:\n",
        "    one_hot = \n",
        "    [[ 0.  0.  0.  1.  0.  0.]\n",
        "     [ 1.  0.  0.  0.  0.  1.]\n",
        "     [ 0.  1.  0.  0.  1.  0.]\n",
        "     [ 0.  0.  1.  0.  0.  0.]]\n",
        "\"\"\"\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test: one_hot_matrix(labels, C)\\nlabels = np.array([1,2,3,0,2,1])\\none_hot = one_hot_matrix(labels, C = 4)\\nprint (\"one_hot = \\n\" + str(one_hot))\\n\\noutput:\\n    one_hot = \\n    [[ 0.  0.  0.  1.  0.  0.]\\n     [ 1.  0.  0.  0.  0.  1.]\\n     [ 0.  1.  0.  0.  1.  0.]\\n     [ 0.  0.  1.  0.  0.  0.]]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RdwASgFlipEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "5297a7f1-12c8-40cf-c8c3-8ea85a3e3c14"
      },
      "source": [
        "def ones(shape):\n",
        "    ones = tf.ones(shape,name=\"ones\")\n",
        "    sess = tf.compat.v1.Session()\n",
        "    ones = sess.run(ones)\n",
        "    \n",
        "    sess.close()\n",
        "    \n",
        "    return ones\n",
        "\n",
        "\"\"\"test: ones(shape)\n",
        "print (\"ones = \" + str(ones([3])))\n",
        "\n",
        "output:\n",
        "    ones = [ 1.  1.  1.]\n",
        "\"\"\"\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test: ones(shape)\\nprint (\"ones = \" + str(ones([3])))\\n\\noutput:\\n    ones = [ 1.  1.  1.]\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU1fI-0nipKk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "deedb872-0810-4e0f-c418-ef67618bee6c"
      },
      "source": [
        "print(testX.shape[0])\n",
        "X_train_flatten = trainX.reshape(trainX.shape[0], -1).T\n",
        "X_test_flatten = testX.reshape(testX.shape[0],-1).T\n",
        "#Normalize\n",
        "X_train = X_train_flatten/255.\n",
        "X_test = X_test_flatten/255.\n",
        "#Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(trainy, 10)  \n",
        "Y_test = convert_to_one_hot(testy, 10)\n",
        "  \n",
        "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000\n",
            "number of training examples = 60000\n",
            "number of test examples = 10000\n",
            "X_train shape: (784, 60000)\n",
            "Y_train shape: (10, 60000)\n",
            "X_test shape: (784, 10000)\n",
            "Y_test shape: (10, 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1s85U5eipM5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "6bf110f0-861f-41ff-b5c4-47ba060b6c09"
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    tf.compat.v1.disable_eager_execution()\n",
        "    X = tf.compat.v1.placeholder(tf.float32,shape=(n_x,None),name=\"X\")\n",
        "    Y = tf.compat.v1.placeholder(tf.float32,shape=(n_y,None),name=\"Y\")\n",
        "    \n",
        "    return X,Y\n",
        "\n",
        "\"\"\"test: create_placeholder(n_x,n_y)\n",
        "X, Y = create_placeholders(12288, 6)\n",
        "print (\"X = \" + str(X))\n",
        "print (\"Y = \" + str(Y))\n",
        "\n",
        "output:\n",
        "    X = Tensor(\"X_3:0\", shape=(12288, None), dtype=float32)\n",
        "    Y = Tensor(\"Y_1:0\", shape=(6, None), dtype=float32)\n",
        "\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test: create_placeholder(n_x,n_y)\\nX, Y = create_placeholders(12288, 6)\\nprint (\"X = \" + str(X))\\nprint (\"Y = \" + str(Y))\\n\\noutput:\\n    X = Tensor(\"X_3:0\", shape=(12288, None), dtype=float32)\\n    Y = Tensor(\"Y_1:0\", shape=(6, None), dtype=float32)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbgCHM-BjKIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "562d5715-92d9-443a-d2f9-175bdbb47a55"
      },
      "source": [
        "def initialize_parameters():\n",
        "    W1 = tf.compat.v1.get_variable(\"W1\",[25,784],initializer = tf.keras.initializers.GlorotNormal(seed=1))\n",
        "    b1 = tf.compat.v1.get_variable(\"b1\",[25,1], initializer= tf.keras.initializers.Zeros())\n",
        "    W2 = tf.compat.v1.get_variable(\"W2\",[12,25],initializer = tf.keras.initializers.GlorotNormal(seed=1))\n",
        "    b2 = tf.compat.v1.get_variable(\"b2\",[12,1], initializer= tf.keras.initializers.Zeros())\n",
        "    W3 = tf.compat.v1.get_variable(\"W3\",[10,12],initializer = tf.keras.initializers.GlorotNormal(seed=1))\n",
        "    b3 = tf.compat.v1.get_variable(\"b3\",[10,1], initializer= tf.keras.initializers.Zeros())\n",
        "    \n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters\n",
        "\n",
        "\"\"\"test: initialize_parameters()\n",
        "tf.compat.v1.reset_default_graph()\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    parameters = initialize_parameters()\n",
        "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
        "    \n",
        "output: \n",
        "    W1 = <tf.Variable 'W1:0' shape=(25, 784) dtype=float32>\n",
        "    b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32>\n",
        "    W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32>\n",
        "    b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32>\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test: initialize_parameters()\\ntf.compat.v1.reset_default_graph()\\nwith tf.compat.v1.Session() as sess:\\n    parameters = initialize_parameters()\\n    print(\"W1 = \" + str(parameters[\"W1\"]))\\n    print(\"b1 = \" + str(parameters[\"b1\"]))\\n    print(\"W2 = \" + str(parameters[\"W2\"]))\\n    print(\"b2 = \" + str(parameters[\"b2\"]))\\n    \\noutput: \\n    W1 = <tf.Variable \\'W1:0\\' shape=(25, 784) dtype=float32>\\n    b1 = <tf.Variable \\'b1:0\\' shape=(25, 1) dtype=float32>\\n    W2 = <tf.Variable \\'W2:0\\' shape=(12, 25) dtype=float32>\\n    b2 = <tf.Variable \\'b2:0\\' shape=(12, 1) dtype=float32>\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkOhIU7gjKLF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "dff34315-0469-4b4e-dfae-938eb3edd268"
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    Z1 = tf.add(tf.matmul(W1,X),b1)                                              # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                              # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2,A1),b2)                                              # Z2 = np.dot(W2, A1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                              # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3,A2),b3)     \n",
        "    \n",
        "    return Z3\n",
        "\n",
        "\"\"\"forward_propagation(X, parameters)\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    X, Y = create_placeholders(784, 10)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    print(\"Z3 = \" + str(Z3))\n",
        "    \n",
        "output:\n",
        "    Z3 = Tensor(\"Add_2:0\", shape=(10, None), dtype=float32)\n",
        "\"\"\""
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'forward_propagation(X, parameters)\\ntf.compat.v1.reset_default_graph()\\n\\nwith tf.compat.v1.Session() as sess:\\n    X, Y = create_placeholders(784, 10)\\n    parameters = initialize_parameters()\\n    Z3 = forward_propagation(X, parameters)\\n    print(\"Z3 = \" + str(Z3))\\n    \\noutput:\\n    Z3 = Tensor(\"Add_2:0\", shape=(10, None), dtype=float32)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36e-JT-1jKOL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "718d94f9-0b88-4a48-ed2e-acbd6be7033a"
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "    \n",
        "    return cost\n",
        "\n",
        "\"\"\"test: compute_cost(Z3,Y)\n",
        "tf.compat.v1.reset_default_graph()\n",
        "\n",
        "with tf.compat.v1.Session() as sess:\n",
        "    X, Y = create_placeholders(784, 10)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    print(\"cost = \" + str(cost))\n",
        "    \n",
        "output:\n",
        "    cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
        "\"\"\""
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'test: compute_cost(Z3,Y)\\ntf.compat.v1.reset_default_graph()\\n\\nwith tf.compat.v1.Session() as sess:\\n    X, Y = create_placeholders(784, 10)\\n    parameters = initialize_parameters()\\n    Z3 = forward_propagation(X, parameters)\\n    cost = compute_cost(Z3, Y)\\n    print(\"cost = \" + str(cost))\\n    \\noutput:\\n    cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzL0IpiozKvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate=0.001, num_epochs= 1500, minibatch_size=262144, print_cost=True):\n",
        "    tf.compat.v1.reset_default_graph() \n",
        "    (n_x,m) = X_train.shape\n",
        "    n_y = Y_train.shape[0]\n",
        "    costs=[]\n",
        "    \n",
        "    X,Y = create_placeholders(n_x,n_y)\n",
        "    \n",
        "    parameters = initialize_parameters()\n",
        "    \n",
        "    Z3 = forward_propagation(X,parameters)\n",
        "    \n",
        "    cost = compute_cost(Z3,Y)\n",
        "    \n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    \n",
        "    init = tf.compat.v1.global_variables_initializer()\n",
        "    \n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        sess.run(init)\n",
        "        \n",
        "        for epoch in range(num_epochs):\n",
        "            epoch_cost = 0\n",
        "            num_minibatches = int(m/minibatch_size)\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size)\n",
        "            \n",
        "            for minibatch in minibatches:\n",
        "                (minibatch_X,minibatch_Y) = minibatch\n",
        "                \n",
        "                _ , minibatch_cost = sess.run([optimizer,cost], feed_dict={X:minibatch_X,Y:minibatch_Y})\n",
        "                \n",
        "                epoch_cost += minibatch_cost / minibatch_size\n",
        "                #print(epoch)\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per fives)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print (\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohVIjphuipPw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 672
        },
        "outputId": "889b933e-2c82-4f8d-fd69-d839e72bf396"
      },
      "source": [
        "parameters = model(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Cost after epoch 0: 0.000009\n",
            "Cost after epoch 100: 0.000002\n",
            "Cost after epoch 200: 0.000001\n",
            "Cost after epoch 300: 0.000001\n",
            "Cost after epoch 400: 0.000001\n",
            "Cost after epoch 500: 0.000001\n",
            "Cost after epoch 600: 0.000001\n",
            "Cost after epoch 700: 0.000000\n",
            "Cost after epoch 800: 0.000000\n",
            "Cost after epoch 900: 0.000000\n",
            "Cost after epoch 1000: 0.000000\n",
            "Cost after epoch 1100: 0.000000\n",
            "Cost after epoch 1200: 0.000000\n",
            "Cost after epoch 1300: 0.000000\n",
            "Cost after epoch 1400: 0.000000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Parameters have been trained!\n",
            "Train Accuracy: 0.9865\n",
            "Test Accuracy: 0.9593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8ZXrN5xmA8R",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}